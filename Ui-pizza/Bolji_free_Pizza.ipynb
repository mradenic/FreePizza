{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Podaci koje gledamo su zadani u train.json i test.json. Stoga prvo moramo učitati  i spremiti podatke iz danih datoteka.\n",
    "\n",
    "JSON datoteka je datoteka koja pohranjuje jednostavne strukture podataka i objekte u formatu JavaScript Object Notation, koji je standardni format za razmjenu podataka. Najviše se koristi za prijenos podataka između web-aplikacije i poslužitelja. One su temeljene na teksu, lako čitljive i mogu se uređivati pomoću uređivača teksta."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "for name in ['train', 'test']:\n",
    "    df = pd.read_json('%s.json' % name)\n",
    "    df['_data'] = name\n",
    "    dfs[name] = df"
   ]
  },
  {
   "source": [
    "Koristeći funkciju append spajamo podatke iz 'train' i 'test' datoteka unutar 'df' i zatim ograničavamo podatke na zajedničke stupce te uključujemo indikator za predviđanje uspjeha zahtjeva."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = dfs['train'].append(dfs['test'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "cols = list(dfs['test'].columns) + ['requester_received_pizza']\n",
    "df = df[cols]\n"
   ]
  },
  {
   "source": [
    "Nakon što smo preimenovali stupce radi preglednosti, pretvaramo varijablu 'got_pizza' u integer, izbacujemo neiskorištene stupce te na kraju spajamo 'title' i 'body' stupce. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\n",
    "        'request_title': 'title', \n",
    "        'request_text_edit_aware': 'body',\n",
    "        'requester_received_pizza': 'got_pizza',\n",
    "}, inplace=True)\n",
    "\n",
    "df['got_pizza'] = df['got_pizza'].apply(lambda x: -1 if pd.isnull(x) else int(x))\n",
    "\n",
    "cols_to_keep = ['_data', 'request_id', 'title', 'body', 'got_pizza']\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "df.iloc[0]\n",
    "\n",
    "df['txt_raw'] = df['title'] + ' ' + df['body']"
   ]
  },
  {
   "source": [
    "U NLTK-u postoje tzv. 'stopwords' odnosno riječi koje nam ne daju nikakvo značenje o samoj rečenici te izbacivanjem istih ne mijenjamo strukturu i značenje te rečenica. Te riječi učitavamo pomoću naredbe 'from nltk.corpus import stopwords'. \n",
    "\n",
    "Uz izbacivanje 'stopwords', također preoblikujemo tekst tako što sva slova pretvaramo u mala slova, te se riješavamo stvari (znakovi i sl.) koje nam nisu od koristi za daljnji rad i rezultat algoritma.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_txt(raw, remove_stop=False):\n",
    "    \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw) \n",
    "\n",
    "    words = letters_only.lower().split()                             \n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return \" \".join(words)\n",
    "\n",
    "df['txt_clean'] = df['txt_raw'].apply(clean_txt)"
   ]
  },
  {
   "source": [
    "Skup podataka ćemo pripremiti za daljnju obradu unutar algoritma tako što ćemo konstruirati numeričko polje koje predstavlja znakove iz teksta transformirane u brojeve radi lakše buduće implementacije i obrade algoritma. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy(vectorizer=None, txt_col='txt_clean'):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "        \n",
    "    dg = df[df['_data'] == 'train']\n",
    "\n",
    "    X = vectorizer.fit_transform(dg[txt_col]).toarray()\n",
    "    y = dg['got_pizza'].astype(int).to_numpy()\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "source": [
    "Nakon nasumične podijele skupa podataka za treniranje isprobavamo naivni Bayesov model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_xy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "\n",
    "print (\"Tocnost na skupu podataka za treniranje: %f\" % model.score(X_train, y_train))\n",
    "print (\"Tocnost na skupu podataka za testiranje: %f\" % model.score(X_test, y_test))\n",
    "\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "print (\"AUC: %f\" % auc(fpr, tpr))"
   ]
  },
  {
   "source": [
    "Tocnost na skupu podataka za treniranje: 0.885149\n",
    "\n",
    "Tocnost na skupu podataka za testiranje: 0.717822\n",
    "\n",
    "AUC: 0.512876"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "U implementaciji algoritma koristimo dijagnostičke alate 'roc' i 'auc' koji nam pomažu interpretirati vjerojatnosnu prognozu problema klasificiranja prediktivnog modeliranja zbog određivanja polarnosti zahtjeva. Na temelju toga donosimo predviđanje uspješnosti tog istog zahtjeva.\n",
    "\n",
    "Biramo vrijednosti koje maksimiziraju varijable 'roc' i 'auc' te nakon toga prolazimo kroz petlju varijabli kako bismo pronašli optimalne vrijednosti."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [1, 5, 10, 25]\n",
    "min_dfs = [0.001, 0.01, 0.02, 0.05]\n",
    "\n",
    "best_alpha, best_min_df = None, None\n",
    "max_auc = -np.inf\n",
    "\n",
    "for alpha in alphas:\n",
    "    for min_df in min_dfs:\n",
    "        \n",
    "        vectorizer = CountVectorizer(min_df = min_df)\n",
    "\n",
    "        X, y = get_xy(vectorizer)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=123)\n",
    "\n",
    "        model = MultinomialNB(alpha=alpha).fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict_proba(X_test)[:, 1]        \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "        auc_val = auc(fpr, tpr)\n",
    "\n",
    "        if auc_val > max_auc:\n",
    "            max_auc = auc_val\n",
    "            best_alpha, best_min_df = alpha, min_df \n",
    "\n",
    "                \n",
    "print (\"alpha: %f\" % best_alpha)\n",
    "print (\"min_df: %f\" % best_min_df)\n",
    "print (\"best auc: %f\" % max_auc)"
   ]
  },
  {
   "source": [
    "alpha: 5.000000\n",
    "\n",
    "min_df: 0.020000\n",
    "\n",
    "best auc: 0.605254"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Provjeravamo je li sada model poboljšan."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = best_min_df)\n",
    "\n",
    "X, y = get_xy(vectorizer)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1234)\n",
    "\n",
    "model = MultinomialNB(alpha=best_alpha).fit(X_train, y_train)\n",
    "\n",
    "print (\"Tocnost na skupu podataka za treniranje: %f\" % model.score(X_train, y_train))\n",
    "print (\"Tocnost na skupu podataka za testiranje:     %f\" % model.score(X_test, y_test))"
   ]
  },
  {
   "source": [
    "Tocnost na skupu podataka za treniranje: 0.757756\n",
    "\n",
    "Tocnost na skupu podataka za testiranje: 0.724752"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Treniramo cijeli skup podataka za treniranje sa najboljim parametrima te spremamo predviđanja. Zatim kreiramo csv datoteku."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df = best_min_df)\n",
    "\n",
    "X, y = get_xy(vectorizer)\n",
    "\n",
    "model = MultinomialNB(alpha=best_alpha).fit(X, y)\n",
    "\n",
    "df_test = df[df['_data'] == 'test'].copy()\n",
    "X_test = vectorizer.transform(df_test['txt_clean'])\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "df_test['requester_received_pizza'] = y_pred\n",
    "final_df = df_test[['request_id', 'requester_received_pizza']]\n",
    "\n",
    "final_df.to_csv('sampleSubmission.csv', index=False)"
   ]
  },
  {
   "source": [
    "Za kraj pogledajmo koji skup riječi najbolje garantira uspješnost zahtjeva."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(X.shape[1])\n",
    "probs = model.predict_proba(x)[:, 1]\n",
    "\n",
    "word_df = pd.DataFrame()\n",
    "word_df['word'] = words\n",
    "word_df['P(pizza | word)'] = probs\n",
    "word_df.sort_values('P(pizza | word)', ascending=False, inplace=True)\n",
    "\n",
    "print ('good words')\n",
    "print (word_df.head(10))\n",
    "print ('\\n---\\n')\n",
    "print ('bad words')\n",
    "print (word_df.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good words\n",
    "           word  P(pizza | word)\n",
    "161         jpg         0.427790\n",
    "268        rice         0.383345\n",
    "157       imgur         0.364823\n",
    "325       tight         0.363433\n",
    "141     helping         0.361993\n",
    "235      person         0.354807\n",
    "345  unemployed         0.344983\n",
    "231    paycheck         0.338030\n",
    "233      paying         0.337769\n",
    "50        check         0.336646\n",
    "\n",
    "---\n",
    "\n",
    "bad words\n",
    "         word  P(pizza | word)\n",
    "34   birthday         0.181946\n",
    "169     leave         0.180133\n",
    "104   florida         0.175216\n",
    "326      till         0.172488\n",
    "112   friends         0.165682\n",
    "20       area         0.162599\n",
    "108      free         0.159392\n",
    "285   sitting         0.159047\n",
    "307  studying         0.155792\n",
    "111    friend         0.143568"
   ]
  }
 ]
}